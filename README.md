# ğŸ§  Maze Gesture Backend (Production)
Backend API for interpreting hand gestures to control a maze game. Serves a trained ML model via FastAPI, supports image-based inference, and includes Dockerized deployment with Prometheus and Grafana monitoring.

This is the backend service for the Maze Gesture Final Project.  
It uses a trained hand gesture recognition model to detect gestures like **left**, **right**, **up**, and **down** from 21-point hand landmarks.

---
ğŸ® Game Demo
Hereâ€™s a quick preview of the gesture-controlled maze game in action:

https://github.com/user-attachments/assets/372a40a8-4bf6-42e3-9b04-1df90d3486c8

---

ğŸ“Š Grafana Monitoring Dashboard
This project includes monitoring via Prometheus and Grafana. Metrics such as prediction count, invalid inputs, and server usage are visualized.

Sample Grafana Dashboard:
![Screenshot (314)](https://github.com/user-attachments/assets/5dc7131d-faa6-421d-a4af-2b9ae489e0a1)
![Screenshot (315)](https://github.com/user-attachments/assets/8d1b2324-edca-4c0c-b246-412b574cc7c7)
![Screenshot (316)](https://github.com/user-attachments/assets/0527435e-2651-4e4c-be3b-98a5d2300c9a)
![Screenshot (317)](https://github.com/user-attachments/assets/3c7e337b-910f-406b-8c6a-a34554d803a6)
![Screenshot (318)](https://github.com/user-attachments/assets/64c030b8-51e4-4f0f-afba-240f3d1091b5)
![Screenshot (319)](https://github.com/user-attachments/assets/d8ef758a-dde2-49ae-8112-210c55fb40ed)

---
## ğŸš€ Features Implemented

| Feature                     | Status |
|----------------------------|--------|
| FastAPI backend            | âœ… Done |
| Gesture prediction API     | âœ… Done |
| Unit tests with pytest     | âœ… Done |
| Dockerized API service     | âœ… Done |
| Swagger UI for testing     | âœ… Done |

---

## ğŸ“ Project Structure

maze-gesture-backend/
â”‚

â”œâ”€â”€ app/

â”‚ â”œâ”€â”€ main.py # FastAPI application

â”‚ â””â”€â”€ models/

â”‚ â””â”€â”€ best_model.pkl # Trained model

â”‚

â”œâ”€â”€ tests/

â”‚ â””â”€â”€ test_api.py # Unit tests for the API

â”‚

â”œâ”€â”€ Dockerfile # Docker image for the API

â”œâ”€â”€ docker-compose.yml # App + Prometheus + Grafana

â”œâ”€â”€ prometheus.yml # Prometheus config

â”œâ”€â”€ Procfile # For Railway deployment

â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .github/workflows/
â”‚ â””â”€â”€ railway-deploy.yml # CI/CD deployment workflow
â””â”€â”€ README.md # You're here :)


---

## ğŸ“¦ API: How to Use

Start the server locally:

```bash
uvicorn app.main:app --reload

Then open in browser:

ğŸ‘‰ http://localhost:8000/docs (Swagger UI)

âœ‹ POST /predict/
Input:
{
  "landmarks": [0.1, 0.2, 0.3, ..., 0.0]  // total 63 floats
}

Output:
{
  "gesture": "left"
}

ğŸ§ª Unit Testing
Run the tests:

pytest

âœ… Unit Test Coverage
| Test                         | Status |
| ---------------------------- | ------ |
| Valid input (63 landmarks)   | âœ…     | 
| Invalid input (bad length)   | âœ…     |
| Validation errors return 422 | âœ…     |

ğŸ³ Docker Support
Build the image:
docker build -t gesture-backend .
Run the container:
docker run -p 8000:8000 gesture-backend

Open:

ğŸ‘‰ https://mlops-final-project-production-2c88.up.railway.app/docs to test the API

 Model Info
Trained using scikit-learn==1.0.2

RandomForestClassifier

21 hand landmarks Ã— 3 coordinates = 63 features

Classes: left, right, up, down

ğŸ“ˆ Monitoring: Prometheus + Grafana
Tracked Metrics

| Metric Name              | Type           | Description                                        |
| ------------------------ | -------------- | -------------------------------------------------- |
| `model_prediction_total` | Model-related  | Total number of predictions made                   |
| `invalid_input_total`    | Data-related   | Count of malformed/invalid inputs                  |
| `http_requests_total`    | Server-related | Auto-exposed: tracks HTTP traffic by status/method |

Prometheus & Grafana
Launch with:

docker-compose up --build

Prometheus: http://localhost:9090

Grafana: http://localhost:3000

Grafana Dashboard imported using ID: 11074

Railway
CI/CD via GitHub Actions (.github/workflows/railway-deploy.yml)

Auto-deploys on push to main

Live API URL:
ğŸ”— https://maze-gesture-backend-production.up.railway.app/docs

ğŸŒ GitHub Pages (Frontend)
Frontend Maze Game is integrated with this backend.
ğŸ“¦ Live Game:
ğŸ‘‰ https://israamohamedgaber.github.io/maze-gesture-backend/

ğŸ§  Model Info
Trained using scikit-learn==1.0.2

Model: RandomForestClassifier

Features: 21 hand landmarks Ã— 3 (x, y, z) = 63 floats

Classes: "left", "right", "up", "down"

ğŸ”— Repository
gesture-maze-research: https://github.com/IsraaMohamedGaber/gesture-maze-research
Backend: https://github.com/IsraaMohamedGaber/maze-gesture-backend


