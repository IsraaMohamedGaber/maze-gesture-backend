# maze-gesture-backend
Backend API for interpreting hand gestures to control a maze game. Serves a trained ML model via FastAPI, supports image-based inference, and includes Dockerized deployment with Prometheus and Grafana monitoring.


---

### ðŸš€ `feature/api` Branch â€“ FastAPI Model Serving API

```markdown
# ðŸš€ FastAPI API â€“ Hand Gesture Model

This branch adds a REST API endpoint using FastAPI that predicts gestures based on hand landmarks.

---

## ðŸ“Œ Endpoint

```http
POST /predict/

Body:

{
  "landmarks": [0.1, 0.2, ..., 0.3]  // 63 float values
}


Response:

{
  "gesture": "left"
}


 Model
Model used: best_model.pkl (RandomForestClassifier)

Trained to classify: left, right, up, down


âœ… Features
| Feature                  | Status |
| ------------------------ | ------ |
| `/predict` route created | âœ… Done |
| Model loaded with joblib | âœ… Done |
| Validates input size     | âœ… Done |
| Returns gesture as JSON  | âœ… Done |



